#!/usr/bin/env python3
"""
Universal spatial transcriptomics analysis script for HEST samples
Usage: python analyze_hest_universal.py <SAMPLE_ID>
"""

import os
import sys
import numpy as np
import scanpy as sc
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import pearsonr, spearmanr
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.cluster import KMeans
import warnings
import argparse
from datetime import datetime
import logging

warnings.filterwarnings('ignore')

# Set scanpy settings
sc.settings.verbosity = 3
sc.settings.set_figure_params(dpi=80, facecolor='white')

def setup_logging(sample_id, output_dir):
    """è®¾ç½®æ—¥å¿—"""
    log_dir = os.path.join(output_dir, "logs")
    os.makedirs(log_dir, exist_ok=True)
    
    log_file = os.path.join(log_dir, f"{sample_id}_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log")
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file),
            logging.StreamHandler(sys.stdout)
        ]
    )
    return logging.getLogger(__name__)

def load_and_preprocess_data(sample_id, config):
    """åŠ è½½å’Œé¢„å¤„ç†æ•°æ®"""
    logger = logging.getLogger(__name__)
    
    # åŠ è½½é¢„æµ‹ç»“æœ
    pred_file = os.path.join(config['output_dir'], sample_id, "predictions", f"{sample_id}_pred.h5ad")
    if not os.path.isfile(pred_file):
        raise FileNotFoundError(f"Prediction file not found: {pred_file}")
    
    adata_pred = sc.read_h5ad(pred_file)
    logger.info(f"Loaded prediction data: {adata_pred.shape}")
    
    # åŠ è½½åŸå§‹æ•°æ®ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
    original_file = os.path.join(config['data_dir'], 'st', f'{sample_id}.h5ad')
    adata_orig = None
    if os.path.isfile(original_file):
        adata_orig = sc.read_h5ad(original_file)
        logger.info(f"Loaded original data: {adata_orig.shape}")
    else:
        logger.warning(f"Original data not found: {original_file}")
    
    return adata_pred, adata_orig

def basic_qc_and_filtering(adata):
    """åŸºæœ¬è´¨é‡æ§åˆ¶å’Œè¿‡æ»¤"""
    logger = logging.getLogger(__name__)
    
    # æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©ºæˆ–å…¨ä¸º0
    if adata.X.size == 0:
        logger.warning("Data is empty!")
        return adata
    
    # æ£€æŸ¥æ˜¯å¦æœ‰NaNå€¼
    if hasattr(adata.X, 'toarray'):
        X_array = adata.X.toarray()
    else:
        X_array = adata.X
    
    nan_count = np.isnan(X_array).sum()
    zero_count = (X_array == 0).sum()
    total_count = X_array.size
    
    logger.info(f"Data quality check:")
    logger.info(f"  - Total values: {total_count}")
    logger.info(f"  - NaN values: {nan_count} ({nan_count/total_count*100:.2f}%)")
    logger.info(f"  - Zero values: {zero_count} ({zero_count/total_count*100:.2f}%)")
    logger.info(f"  - Non-zero values: {total_count - zero_count - nan_count}")
    
    # å¦‚æœæ•°æ®å…¨ä¸º0æˆ–NaNï¼Œè·³è¿‡è¿‡æ»¤
    if zero_count + nan_count == total_count:
        logger.warning("All values are 0 or NaN - skipping filtering")
        return adata
    
    # è®¡ç®—åŸºæœ¬ç»Ÿè®¡
    sc.pp.calculate_qc_metrics(adata, inplace=True)
    
    # è¿‡æ»¤ä½è´¨é‡spotså’ŒåŸºå› ï¼ˆåªæœ‰åœ¨æ•°æ®æœ‰æ•ˆæ—¶ï¼‰
    if adata.n_obs > 0 and adata.n_vars > 0:
        try:
            sc.pp.filter_cells(adata, min_genes=1)  # é™ä½é˜ˆå€¼
            sc.pp.filter_genes(adata, min_cells=1)  # é™ä½é˜ˆå€¼
            logger.info(f"After filtering: {adata.shape}")
        except:
            logger.warning("Filtering failed, keeping original data")
    
    return adata

def normalize_and_scale(adata):
    """æ ‡å‡†åŒ–å’Œç¼©æ”¾"""
    logger = logging.getLogger(__name__)
    
    # æ£€æŸ¥æ•°æ®æ˜¯å¦æœ‰æ•ˆ
    if adata.X.size == 0:
        logger.warning("Data is empty - skipping normalization")
        return adata
    
    if hasattr(adata.X, 'toarray'):
        X_array = adata.X.toarray()
    else:
        X_array = adata.X
    
    # æ£€æŸ¥æ˜¯å¦å…¨ä¸º0æˆ–NaN
    if np.all(X_array == 0) or np.all(np.isnan(X_array)):
        logger.warning("All values are 0 or NaN - skipping normalization")
        return adata
    
    try:
        # æ ‡å‡†åŒ–åˆ°10,000 reads per cell
        sc.pp.normalize_total(adata, target_sum=1e4)
        
        # Log transform
        sc.pp.log1p(adata)
        
        # è¯†åˆ«é«˜å˜å¼‚åŸºå› ï¼ˆé™ä½é˜ˆå€¼ï¼‰
        sc.pp.highly_variable_genes(adata, min_mean=0.001, max_mean=10, min_disp=0.1)
        logger.info(f"Highly variable genes: {sum(adata.var.highly_variable)}")
        
        # ç¼©æ”¾åˆ°å•ä½æ–¹å·®
        sc.pp.scale(adata, max_value=10)
        
    except Exception as e:
        logger.warning(f"Normalization failed: {e}")
        logger.info("Proceeding with raw data")
    
    return adata

def dimensionality_reduction(adata):
    """é™ç»´åˆ†æ"""
    logger = logging.getLogger(__name__)
    
    # æ£€æŸ¥æ•°æ®æ˜¯å¦æœ‰æ•ˆ
    if adata.X.size == 0:
        logger.warning("Data is empty - skipping dimensionality reduction")
        return adata
    
    try:
        # PCA
        sc.tl.pca(adata, use_highly_variable=True, svd_solver='arpack')
        
        # è®¡ç®—é‚»å±…å›¾
        sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40)
        
        # UMAP
        sc.tl.umap(adata)
        
        # t-SNE
        sc.tl.tsne(adata, use_rep='X_pca')
        
        logger.info(f"PCA components: {adata.obsm['X_pca'].shape}")
        
    except Exception as e:
        logger.warning(f"Dimensionality reduction failed: {e}")
    
    return adata

def clustering_analysis(adata):
    """èšç±»åˆ†æ"""
    logger = logging.getLogger(__name__)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰PCAç»“æœ
    if 'X_pca' not in adata.obsm:
        logger.warning("No PCA results - skipping clustering")
        return adata
    
    try:
        # Leidenèšç±»
        sc.tl.leiden(adata, resolution=0.5)
        
        # Louvainèšç±»
        sc.tl.louvain(adata, resolution=0.5)
        
        # K-meansèšç±»ï¼ˆåŸºäºPCAï¼‰
        pca_data = adata.obsm['X_pca'][:, :20]
        kmeans = KMeans(n_clusters=8, random_state=42)
        adata.obs['kmeans_clusters'] = kmeans.fit_predict(pca_data)
        
        logger.info(f"Clustering results:")
        logger.info(f"  - Leiden clusters: {adata.obs['leiden'].nunique()}")
        logger.info(f"  - Louvain clusters: {adata.obs['louvain'].nunique()}")
        logger.info(f"  - K-means clusters: {adata.obs['kmeans_clusters'].nunique()}")
        
    except Exception as e:
        logger.warning(f"Clustering failed: {e}")
    
    return adata

def differential_expression_analysis(adata):
    """å·®å¼‚è¡¨è¾¾åˆ†æ"""
    logger = logging.getLogger(__name__)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰èšç±»ç»“æœ
    if 'leiden' not in adata.obs.columns:
        logger.warning("No clustering results - skipping DE analysis")
        return adata
    
    try:
        # ä½¿ç”¨Leidenèšç±»è¿›è¡Œå·®å¼‚è¡¨è¾¾åˆ†æ
        sc.tl.rank_genes_groups(adata, 'leiden', method='wilcoxon')
        
        # è·å–æ¯ä¸ªclusterçš„markeråŸºå› 
        result = adata.uns['rank_genes_groups']
        groups = result['names'].dtype.names
        
        logger.info(f"DE analysis completed for {len(groups)} clusters")
        
        # æ˜¾ç¤ºæ¯ä¸ªclusterçš„top markeråŸºå› 
        for group in groups[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªclusters
            logger.info(f"Cluster {group} top markers:")
            for i in range(min(5, len(result['names'][group]))):
                gene = result['names'][group][i]
                score = result['scores'][group][i]
                logger.info(f"  {gene}: {score:.3f}")
        
    except Exception as e:
        logger.warning(f"DE analysis failed: {e}")
    
    return adata

def visualization_plots(adata, adata_orig, sample_id, output_dir):
    """å¯è§†åŒ–å›¾è¡¨"""
    logger = logging.getLogger(__name__)
    
    viz_dir = os.path.join(output_dir, "visualizations")
    os.makedirs(viz_dir, exist_ok=True)
    
    try:
        # è®¾ç½®å›¾å½¢å¤§å°
        plt.rcParams['figure.figsize'] = (12, 8)
        
        # 1. UMAPèšç±»å›¾
        if 'X_umap' in adata.obsm and 'leiden' in adata.obs.columns:
            fig, axes = plt.subplots(2, 3, figsize=(18, 12))
            
            # UMAP with different clustering methods
            sc.pl.umap(adata, color='leiden', ax=axes[0,0], show=False, title='Leiden Clustering')
            sc.pl.umap(adata, color='louvain', ax=axes[0,1], show=False, title='Louvain Clustering')
            sc.pl.umap(adata, color='kmeans_clusters', ax=axes[0,2], show=False, title='K-means Clustering')
            
            # t-SNE plots
            sc.pl.tsne(adata, color='leiden', ax=axes[1,0], show=False, title='t-SNE Leiden')
            sc.pl.tsne(adata, color='louvain', ax=axes[1,1], show=False, title='t-SNE Louvain')
            sc.pl.tsne(adata, color='kmeans_clusters', ax=axes[1,2], show=False, title='t-SNE K-means')
            
            plt.tight_layout()
            plt.savefig(os.path.join(viz_dir, 'clustering_analysis.png'), dpi=300, bbox_inches='tight')
            plt.close()
            logger.info("Saved clustering analysis plots")
        
        # 2. ç©ºé—´èšç±»å›¾
        if 'spatial' in adata.obsm and 'leiden' in adata.obs.columns:
            fig, axes = plt.subplots(1, 3, figsize=(18, 6))
            
            sc.pl.spatial(adata, color='leiden', ax=axes[0], show=False, title='Spatial Leiden')
            sc.pl.spatial(adata, color='louvain', ax=axes[1], show=False, title='Spatial Louvain')
            sc.pl.spatial(adata, color='kmeans_clusters', ax=axes[2], show=False, title='Spatial K-means')
            
            plt.tight_layout()
            plt.savefig(os.path.join(viz_dir, 'spatial_clustering.png'), dpi=300, bbox_inches='tight')
            plt.close()
            logger.info("Saved spatial clustering plots")
        
        # 3. å·®å¼‚è¡¨è¾¾çƒ­å›¾
        if 'rank_genes_groups' in adata.uns:
            sc.pl.rank_genes_groups_heatmap(adata, n_genes=10, use_raw=False, 
                                           save=f'_{sample_id}_marker_genes_heatmap.png')
            logger.info("Saved marker genes heatmap")
        
        # 4. åŸºå› è¡¨è¾¾ç©ºé—´å›¾ï¼ˆé€‰æ‹©å‡ ä¸ªmarkeråŸºå› ï¼‰
        if 'spatial' in adata.obsm and 'rank_genes_groups' in adata.uns:
            # è·å–top markeråŸºå› 
            top_genes = []
            for group in adata.uns['rank_genes_groups']['names'].dtype.names[:3]:
                top_genes.extend(adata.uns['rank_genes_groups']['names'][group][:3])
            
            # ç»˜åˆ¶ç©ºé—´è¡¨è¾¾å›¾
            fig, axes = plt.subplots(3, 3, figsize=(15, 15))
            axes = axes.flatten()
            
            for i, gene in enumerate(top_genes[:9]):
                if gene in adata.var_names:
                    sc.pl.spatial(adata, color=gene, ax=axes[i], show=False, 
                                 title=f'{gene} Expression', use_raw=False)
            
            plt.tight_layout()
            plt.savefig(os.path.join(viz_dir, 'spatial_gene_expression.png'), dpi=300, bbox_inches='tight')
            plt.close()
            logger.info("Saved spatial gene expression plots")
        
        # 5. ä¸åŸå§‹æ•°æ®å¯¹æ¯”ï¼ˆå¦‚æœæœ‰ï¼‰
        if adata_orig is not None:
            try:
                # æ‰¾åˆ°å…±åŒçš„åŸºå› 
                common_genes = set(adata.var_names) & set(adata_orig.var_names)
                if len(common_genes) > 0:
                    common_genes = list(common_genes)[:5]  # é€‰æ‹©å‰5ä¸ªåŸºå› 
                    
                    fig, axes = plt.subplots(2, len(common_genes), figsize=(4*len(common_genes), 8))
                    
                    for i, gene in enumerate(common_genes):
                        # é¢„æµ‹ç»“æœ
                        sc.pl.spatial(adata, color=gene, ax=axes[0, i], show=False, 
                                     title=f'Predicted {gene}', use_raw=False)
                        # åŸå§‹æ•°æ®
                        sc.pl.spatial(adata_orig, color=gene, ax=axes[1, i], show=False, 
                                     title=f'Original {gene}', use_raw=False)
                    
                    plt.tight_layout()
                    plt.savefig(os.path.join(viz_dir, 'prediction_vs_original.png'), dpi=300, bbox_inches='tight')
                    plt.close()
                    logger.info("Saved prediction vs original comparison plots")
            except:
                logger.warning("Could not create comparison plots")
        
        logger.info("All visualization plots saved")
        
    except Exception as e:
        logger.warning(f"Visualization failed: {e}")

def quality_assessment(adata, adata_orig, sample_id):
    """è´¨é‡è¯„ä¼°"""
    logger = logging.getLogger(__name__)
    
    # 1. è¡¨è¾¾åˆ†å¸ƒ
    logger.info("Expression distribution:")
    if hasattr(adata.X, 'toarray'):
        X_array = adata.X.toarray()
    else:
        X_array = adata.X
    
    logger.info(f"  - Mean expression: {np.mean(X_array):.4f}")
    logger.info(f"  - Std expression: {np.std(X_array):.4f}")
    logger.info(f"  - Zero rate: {(X_array == 0).sum() / X_array.size:.2%}")
    
    # 2. èšç±»è´¨é‡
    logger.info("Clustering quality:")
    for method in ['leiden', 'louvain', 'kmeans_clusters']:
        if method in adata.obs.columns:
            n_clusters = adata.obs[method].nunique()
            logger.info(f"  - {method}: {n_clusters} clusters")
    
    # 3. ä¸åŸå§‹æ•°æ®å¯¹æ¯”ï¼ˆå¦‚æœæœ‰ï¼‰
    if adata_orig is not None:
        try:
            # æ‰¾åˆ°å…±åŒåŸºå› 
            common_genes = set(adata.var_names) & set(adata_orig.var_names)
            if len(common_genes) > 0:
                common_genes = list(common_genes)[:100]  # é€‰æ‹©å‰100ä¸ªåŸºå› 
                
                # è®¡ç®—ç›¸å…³æ€§
                pred_idx = [list(adata.var_names).index(g) for g in common_genes]
                orig_idx = [list(adata_orig.var_names).index(g) for g in common_genes]
                
                correlations = []
                for p_idx, o_idx in zip(pred_idx, orig_idx):
                    try:
                        corr = pearsonr(adata.X[:, p_idx], adata_orig.X[:, o_idx])[0]
                        correlations.append(corr)
                    except:
                        correlations.append(np.nan)
                
                correlations = [c for c in correlations if not np.isnan(c)]
                if correlations:
                    logger.info(f"Prediction vs Original correlation:")
                    logger.info(f"  - Mean Pearson r: {np.mean(correlations):.4f}")
                    logger.info(f"  - Median Pearson r: {np.median(correlations):.4f}")
                    logger.info(f"  - Correlation range: [{np.min(correlations):.4f}, {np.max(correlations):.4f}]")
        except:
            logger.warning("Could not calculate prediction vs original correlation")
    
    return adata

def save_analysis_results(adata, sample_id, output_dir):
    """ä¿å­˜åˆ†æç»“æœ"""
    logger = logging.getLogger(__name__)
    
    analysis_dir = os.path.join(output_dir, "analysis")
    os.makedirs(analysis_dir, exist_ok=True)
    
    try:
        # ä¿å­˜å¤„ç†åçš„æ•°æ®
        processed_file = os.path.join(analysis_dir, f"{sample_id}_analyzed.h5ad")
        adata.write_h5ad(processed_file)
        logger.info(f"Saved processed data to: {processed_file}")
        
        # ä¿å­˜èšç±»ç»“æœ
        cluster_columns = [col for col in ['leiden', 'louvain', 'kmeans_clusters'] if col in adata.obs.columns]
        if cluster_columns:
            cluster_results = adata.obs[cluster_columns].copy()
            cluster_file = os.path.join(analysis_dir, "clustering_results.csv")
            cluster_results.to_csv(cluster_file)
            logger.info(f"Saved clustering results to: {cluster_file}")
        
        # ä¿å­˜markeråŸºå› 
        if 'rank_genes_groups' in adata.uns:
            result = adata.uns['rank_genes_groups']
            groups = result['names'].dtype.names
            
            marker_genes = {}
            for group in groups:
                genes = result['names'][group][:20]  # Top 20 genes
                scores = result['scores'][group][:20]
                marker_genes[group] = list(zip(genes, scores))
            
            # ä¿å­˜ä¸ºCSV
            max_genes = max(len(genes) for genes in marker_genes.values())
            df_markers = pd.DataFrame(index=range(max_genes))
            
            for group, genes in marker_genes.items():
                gene_names = [g[0] for g in genes]
                gene_scores = [g[1] for g in genes]
                
                # å¡«å……åˆ°ç›¸åŒé•¿åº¦
                while len(gene_names) < max_genes:
                    gene_names.append('')
                    gene_scores.append(np.nan)
                
                df_markers[f'{group}_gene'] = gene_names
                df_markers[f'{group}_score'] = gene_scores
            
            marker_file = os.path.join(analysis_dir, "marker_genes.csv")
            df_markers.to_csv(marker_file, index=False)
            logger.info(f"Saved marker genes to: {marker_file}")
        
        logger.info("All analysis results saved")
        
    except Exception as e:
        logger.warning(f"Failed to save results: {e}")

def analyze_sample(sample_id, config):
    """å¯¹å•ä¸ªæ ·æœ¬è¿›è¡Œåˆ†æ"""
    logger = logging.getLogger(__name__)
    
    logger.info(f"Starting analysis for sample: {sample_id}")
    
    # æ£€æŸ¥è¾“å‡ºç›®å½•
    output_dir = os.path.join(config['output_dir'], sample_id)
    if not os.path.exists(output_dir):
        raise FileNotFoundError(f"Output directory not found: {output_dir}")
    
    # è®¾ç½®æ—¥å¿—
    logger = setup_logging(sample_id, output_dir)
    
    # 1. åŠ è½½æ•°æ®
    adata_pred, adata_orig = load_and_preprocess_data(sample_id, config)
    
    # 2. åŸºæœ¬QCå’Œè¿‡æ»¤
    adata_pred = basic_qc_and_filtering(adata_pred)
    
    # 3. æ ‡å‡†åŒ–å’Œç¼©æ”¾
    adata_pred = normalize_and_scale(adata_pred)
    
    # 4. é™ç»´åˆ†æ
    adata_pred = dimensionality_reduction(adata_pred)
    
    # 5. èšç±»åˆ†æ
    adata_pred = clustering_analysis(adata_pred)
    
    # 6. å·®å¼‚è¡¨è¾¾åˆ†æ
    adata_pred = differential_expression_analysis(adata_pred)
    
    # 7. å¯è§†åŒ–
    visualization_plots(adata_pred, adata_orig, sample_id, output_dir)
    
    # 8. è´¨é‡è¯„ä¼°
    quality_assessment(adata_pred, adata_orig, sample_id)
    
    # 9. ä¿å­˜ç»“æœ
    save_analysis_results(adata_pred, sample_id, output_dir)
    
    logger.info(f"Analysis completed successfully for {sample_id}")
    return output_dir

def main():
    parser = argparse.ArgumentParser(description='Spatial transcriptomics analysis for HEST samples')
    parser.add_argument('sample_id', type=str, help='Sample ID (e.g., MEND159)')
    parser.add_argument('--data_dir', type=str, default='data/hest_data', 
                       help='Base directory for HEST data')
    parser.add_argument('--output_dir', type=str, default='output',
                       help='Base directory for output')
    
    args = parser.parse_args()
    
    # é…ç½®
    config = {
        'data_dir': args.data_dir,
        'output_dir': args.output_dir
    }
    
    try:
        output_dir = analyze_sample(args.sample_id, config)
        print(f"âœ… Analysis completed successfully!")
        print(f"ğŸ“ Results saved in: {output_dir}")
    except Exception as e:
        print(f"âŒ Analysis failed: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
